% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%

% По умолчанию используется шрифт 14 размера. Если нужен 12-й шрифт, уберите опцию [14pt]
\documentclass[14pt]{matmex-diploma-custom}
%\documentclass{matmex-diploma}

\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
    %chair              = {Математико - Механический факультет},
    title              = {Рекомендательная система музыки},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {coursework},
    position           = {студента},
    group              = 244,
    author             = {Руденко Дмитрий Андреевич 244 группа},
    %supervisorPosition = {д.\,ф.-м.\,н., профессор},
    %supervisor         = {Выбегалло А.\,А.},
    %reviewerPosition   = {ст. преп.},
    %reviewer           = {Привалов А.\,И.},
    %chairHeadPosition  = {д.\,ф.-м.\,н., профессор},
    %chairHead          = {Хунта К.\,Х.},
    university         = {Санкт-Петербургский Государственный Университет},
    faculty            = {Математико-механический факультет},
    city               = {Санкт-Петербург},
    year               = {2015}
}

\maketitle
\tableofcontents
% У введения нет номера главы
\section*{Введение}
В век интернет-технологий каждый человек имеет доступ к терабайтам аудиофайлов. И каждый хочет найти именно ту музыку, которая ему подходит. Но вручную перебирать тысячи песен очень трудоемко. Поэтому хотелось бы автоматизировать этот процесс. Но как? Уже существуют рекомендательные системы: например, last.fm или vk.com. Но они основаны на коллоборативной фильтрации. Я же сделал систему, которая строит рекомендательную модель именно на анализе самих ауйдиофайлов, которые пользователь отметил как понравившиеся или не понравившиеся.

\section{Постановка задачи}
Целью данной работы является реализация приложения, которое по готовому набору пользовательской музыки формировало бы систему, способную определять, понравится ли конкректный аудиофайл пользователю. Необходимо реализовать следующие компоненты:
\begin{itemize}
\item{Чтение пользовательского набора wav файлов}
\item{Обработка начальных данных}
\item{Построение рекомендательной модели на основе собранных данных}
\item{Выборка подходящих wav файлов из нового набора}
\end{itemize}

Дополнительные задачи: разобраться в инструментах Data Maining и FFT на языке Python

\section{Обзор существующих систем}
Существуют несколько систем по рекомендации музыки: например, last.fm, vk.com, spotify. Имея неполный список предпочтений пользователя, их рекомендательные системы предсказывают, какая музыка понравится ему. Кроме того, существует дочернее предприятие Spotify The Echo Nest, которое предоставляет пользователям по всему миру огромную базу данных по анализу музыки. Но опять таки, в этой базе может не содержаться тех аудиофайлов, которые именно пользователь выбрал. 

\section{Решение задачи}
Для работы был выбран язык Python, так как на нем реализованы библиотеки NumPy и Sklearn, про которые будет рассказано далее.
 \subsection{Чтение пользовательского набора}
 Составляется два набора данных: аудиозаписи, которые нравятся пользователю и которые нет. Чтение реализовано с помощью стандартных библиотек Python: wave, struct и os.
 \subsection{Обработка начальных данных}
 Анализируемый файл представляется в виде вектора из семплов, который делится на N снимков, каждый из которых приводится в АЧХ при помощи FFT-преобразования. То есть, из временного ряда мы получаем набор амплитут разных частот. FFT преобразоание выполняется с помощью библиотеки NumPy. Далее, для каждого такого снимка считаются следующие статистические величины: среднее значение, медиана, стандартное отклонение, скос (skewness) и крутизна (kurtosis). Соответственно, для каждой композиции после вычислений мы будем иметь 5 * N величин, которые формируют точки в 5N-мерном пространстве.
 \subsection{Построение рекомендательной модели}
 Далее нам требуется, чтобы система умела определять,к какому из классов ("true" или "false") принадлежит новая 5N - мерная точка. Это задача Data Maining: у нас имеется матрица "object - features" и имеется вектор ответов("1" или "0") для каждого из объектов, и по этим данным требуется построить функцию, максимально точно определяющую класс целевого объекта. Изначально была простая идея обобщающего прямоугольника: по каждой из координат у всех понравившихся пользователю композиций выбираются максимум и минимум, а далее проверяем, попадает ли каждая из координат у целевой композиции в промежуток между максимом и минимумом. Минус очевиден: какая-либо композиция, сильно отличающаяся от всех остальных(так называемый "выброс"), очень сильно снижает точность определения класса. Поэтому дальнейший упор был сделан на алгоритмы Data Maining, которые реализованы в библиотеке Sklearn. Для исследования были выбраны следующие алгоритмы: K-means, Linear regression и Support vector clustering("SVC").\paragraph{}Задана обучающая выборка пар «объект-ответ» $X^m = \{(x_1,y_1),\dots,(x_m,y_m)\}$, $a(u)$ - искомая функция
 \begin{itemize}
  \item{
 K-means (k ближайших соседей):Задана метрика $\rho(x,x')$. Для произвольного объекта $u$    расположим объекты обучающей выборки $x_i$ в порядке возрастания расстояний до $u$:
$\rho(u,x_{1; u}) \leq  \rho(u,x_{2; u}) \leq \cdots \leq \rho(u,x_{m; u})$, где через $x_{i; u}$ обозначается тот объект обучающей выборки, который является $i$-м соседом объекта $u$. Аналогичное обозначение введём и для ответа на i-м соседе: $y_{i; u}$. Т.о. $ a(u) = \mathrm{arg}\max_{y\in Y} \sum_{i=1}^m \bigl[ y(x_{i; u})=y \bigr] w(i,u)$, где $w(i,u) = [i\leq k]$.
}

  \item{
  Logistic regression (логистическая регрессия): $a(x) = \mathrm{sign}(\sum_{j=1}^n w_j f_j(x) - w_0)$, где $w_j$ - вес $j$- ого признака, $w_0$ - порог принятия решения, $w=(w_1,\ldots,w_n)$ - вектор весов. Поиск вектора весов по выборке $X^m$ и есть задача алгоритма. В logistic regression она решается следующим образом: $\sum_{i=1}^m \ln(1 + \exp( -y_i \langle x_i,w )) \to \min_{w}$.
}
  \item{
  Support vector clustering(метод опорных векторов): Постановка задачи аналогична logistic regression, отличается лишь задача нахождения оптимального вектора весов $w$ и порога вхождения $w_0$: $\sum_{i = 1}^m(1 - M_i(x, w_0))_+ + \frac{1}{2C}(\left \| w \right \|)^2 \to \min_{w; w_0}$, где $M_i(x, w_0) = y_i(\langle x_i,w \rangle - w_0)$ - отступ объекта $x$
}
\end{itemize}

 \subsection{Выборка подходящих wav файлов из нового набора}
 Обрабатываем новый набор аналогично обработки начальных данных(собираем статистические данные) и для каждого из объектов запрашиваем у построенной модели ответ на вопрос: "К какому классу принадлежит этот объект?". Те из объектов, которые попадут в класс подходящих("True"), и будут искомые
 
\section{Тестирование моделей}
 Для тестирование моделей был взят начальный набор, содержащий 73 wav файла и целевой набор, содержащий 33 wav файла.  Тестирование проводилось с помощью перекрестной проверки(cross validation), которая также реализована в библиотеке Sklearn. Так как перекрестная проверка основывается только на начальном наборе данных, было дополнительно проведено тестирование работы алгоритмов на целевом наборе данных. Здесь и далее N - количество снимков с аудиофайла.


\begin{figure}[h!]
\label{метрики100}
\centering
\includegraphics[width =\textwidth]{knm100.png}
\caption{Тестирование метрик KNN. N = 100}
\end{figure}

\begin{figure}
\label{1метрики1000}
\centering
\includegraphics[width =\textwidth]{knm1000.png}
\caption{Тестирование метрик KNN. N = 1000}
\end{figure}

\begin{figure}
\label{1метрики1000}
\centering
\includegraphics[width =\textwidth]{metric10000.png}
\caption{Тестирование метрик KNN. N = 10000}
\end{figure}

\begin{figure}
\label{Соседи100}
\centering
\includegraphics[width =\textwidth]{knn100.png}
\caption{Тестирование количества соседей KNN. N = 100}
\end{figure}

\begin{figure}
\label{Соседи1000}
\centering
\includegraphics[width =\textwidth]{knn1000.png}
\caption{Тестирование количества соседей KNN. N = 1000}
\end{figure}

\begin{figure}
\label{Соседи1000}
\centering
\includegraphics[width =\textwidth]{neight10000.png}
\caption{Тестирование количества соседей KNN. N = 10000}
\end{figure}

\begin{figure}
\label{C100}
\centering
\includegraphics[width =\textwidth]{testSVCC.png}
\caption{Тестирование константы С SVC. N = 100}
\end{figure}

\begin{figure}
\label{C1000}
\centering
\includegraphics[width =\textwidth]{c1000.png}
\caption{Тестирование константы С SVC. N = 1000}
\end{figure}

\begin{figure}
\label{C1000}
\centering
\includegraphics[width =\textwidth]{c10000.png}
\caption{Тестирование константы С SVC. N = 10000}
\end{figure}


\begin{figure}
\label{батл100}
\centering
\includegraphics[width =\textwidth]{statBattle.png}
\caption{Сравнительный тест итоговых алгоритмов. N = 100}
\end{figure}

\begin{figure}
\label{батл100}
\centering
\includegraphics[width =\textwidth]{battle1000.png}
\caption{Сравнительный тест итоговых алгоритмов. N = 1000}
\end{figure}

\begin{figure}
\label{батл100}
\centering
\includegraphics[width =\textwidth]{battle10000.png}
\caption{Сравнительный тест итоговых алгоритмов. N = 10000}
\end{figure}

\begin{figure}
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    N & SVC & KNN & LogReg \\ \hline
    100 & 75.8 & 78.8 & 63.6\\ \hline
    1000 &75.6 & 72.7 & 72.7 \\ \hline
    10000 &75.6 & 81.8 & 75.6 \\ \hline
    \end{tabular}
    \caption{Тестирование на целевом наборе}
\end{center}
\end{figure}

% У заключения нет номера главы
\section*{Заключение}
В ходе работы были написаны методы для чтения и обработки wav файлов, хранения полученных данных, построения рекомендательной модели на языке Python  с использованием библиотек NumPy и Sklearn.

\section*{Список литературы}
\begin{enumerate}
\item http://www.machinelearning.ru/
\item http://scikit-learn.org/
\item http://www.numpy.org/
\item https://en.wikipedia.org/wiki/Kurtosis
\item https://en.wikipedia.org/wiki/Skewness
\item https://en.wikipedia.org/wiki/FFT
\end{enumerate}
\setmonofont[Mapping=tex-text]{CMU Typewriter Text}
%\bibliographystyle{ugost2008ls}
%\bibliography{diploma.bib}
\end{document}
